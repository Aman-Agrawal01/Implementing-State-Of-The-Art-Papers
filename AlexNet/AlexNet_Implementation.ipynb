{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_Implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOcBzFFiN0H0"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em43pJe2Txf2"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize(224),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='/content/data/',\n",
        "                                             train=True,\n",
        "                                             download=True,\n",
        "                                             transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='/content/data/',\n",
        "                                            train=False,\n",
        "                                            transform=transform,\n",
        "                                            download=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw8hCV20W8gQ"
      },
      "source": [
        "train_data = torch.utils.data.DataLoader(train_dataset,\n",
        "                                         batch_size=100,\n",
        "                                         shuffle=True)\n",
        "\n",
        "test_data = torch.utils.data.DataLoader(test_dataset,\n",
        "                                        batch_size=100,\n",
        "                                        shuffle=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTi8ttlhN-eV"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "\n",
        "    super(AlexNet,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,96,11,4,2)\n",
        "    self.conv2 = nn.Conv2d(96,256,5,1,2)\n",
        "    self.conv3 = nn.Conv2d(256,384,3,1,1)\n",
        "    self.conv4 = nn.Conv2d(384,384,3,1,1)\n",
        "    self.conv5 = nn.Conv2d(384,256,3,1,1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=3,stride=2,padding=0)\n",
        "    self.fc1 = nn.Linear(6*6*256,4096)\n",
        "    self.fc2 = nn.Linear(4096,4096)\n",
        "    self.output_layer = nn.Linear(4096,10)\n",
        "    self.lbn = nn.LocalResponseNorm(size=5,alpha=0.0001,beta=0.75,k=2)\n",
        "    self.dropout = nn.Dropout(p=0.5,inplace=True)\n",
        "    self.relu = nn.ReLU(inplace=False)\n",
        "  \n",
        "  def forward(self,x):\n",
        "\n",
        "    # 1st layer\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.lbn(x)\n",
        "    x = self.pool(x)\n",
        "    \n",
        "\n",
        "    # 2nd layer\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.lbn(x)\n",
        "    x = self.pool(x)\n",
        "    \n",
        "\n",
        "    # 3rd Layer\n",
        "    x = self.conv3(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    # 4th Layer\n",
        "    x = self.conv4(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    # 5th layer\n",
        "    x = self.conv5(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "\n",
        "    # Flatten \n",
        "    x = x.view(x.size(0),-1)\n",
        "\n",
        "    # 6th Layer\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    # 7th Layer\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    # 8th Layer (Output Layer)\n",
        "    x = self.output_layer(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6KcdmZVQpGV",
        "outputId": "19ef5455-00bd-4dc6-bb21-deeb0237eead",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        }
      },
      "source": [
        "model = AlexNet()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "summary(model,input_size=(1,224,224))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          11,712\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            " LocalResponseNorm-3           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-6          [-1, 256, 27, 27]               0\n",
            " LocalResponseNorm-7          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "           Conv2d-11          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-12          [-1, 384, 13, 13]               0\n",
            "           Conv2d-13          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-14          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-15            [-1, 256, 6, 6]               0\n",
            "          Dropout-16                 [-1, 9216]               0\n",
            "           Linear-17                 [-1, 4096]      37,752,832\n",
            "             ReLU-18                 [-1, 4096]               0\n",
            "          Dropout-19                 [-1, 4096]               0\n",
            "           Linear-20                 [-1, 4096]      16,781,312\n",
            "             ReLU-21                 [-1, 4096]               0\n",
            "           Linear-22                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,299,082\n",
            "Trainable params: 58,299,082\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 14.72\n",
            "Params size (MB): 222.39\n",
            "Estimated Total Size (MB): 237.30\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "083V5RHbT9ZU",
        "outputId": "95e6c24d-35da-4eba-f8e0-361c8dcd6327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 10\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "test_loss = []\n",
        "test_acc = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  correct = 0\n",
        "  iterations = 0\n",
        "  iter = 0.0\n",
        "\n",
        "  for batch , (images,labels) in enumerate(train_data):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    loss = loss_function(outputs,labels)\n",
        "    iter = iter + loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    _,pred = torch.max(outputs,1)\n",
        "    correct = correct + (labels==pred).sum().item()\n",
        "\n",
        "    iterations +=1\n",
        "  print('-----------EPOCH '+str(epoch+1)+'------------')\n",
        "  train_loss.append(iter/iterations)\n",
        "  train_acc.append(correct/len(train_dataset))\n",
        "  print('TRAINING LOSS = ' + str(train_loss[epoch]))\n",
        "  print('TRAINING ACCURACY = ' + str(train_acc[epoch]))\n",
        "\n",
        "  correct = 0\n",
        "  iter = 0.0\n",
        "  iterations = 0\n",
        "\n",
        "  for batch , (images,labels) in enumerate(test_data):\n",
        "    if torch.cuda.is_available():\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images)\n",
        "\n",
        "    _,pred = torch.max(outputs,1)\n",
        "    correct = correct + (labels==pred).sum().item()\n",
        "    loss = loss_function(outputs,labels)\n",
        "    iter = iter + loss.item()\n",
        "    iterations += 1\n",
        "\n",
        "  test_loss.append(iter/iterations)\n",
        "  test_acc.append(correct/len(test_dataset))\n",
        "  print('TEST LOSS = ' + str(test_loss[epoch]))\n",
        "  print('TESTING ACCURACY = ' + str(test_acc[epoch]))\n",
        "  print('------------------------------------')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------EPOCH 1------------\n",
            "TRAINING LOSS = 0.34788329200508694\n",
            "TRAINING ACCURACY = 0.8815\n",
            "TEST LOSS = 0.0803766034124419\n",
            "TESTING ACCURACY = 0.974\n",
            "------------------------------------\n",
            "-----------EPOCH 2------------\n",
            "TRAINING LOSS = 0.08363534129108302\n",
            "TRAINING ACCURACY = 0.9753333333333334\n",
            "TEST LOSS = 0.052078438482130875\n",
            "TESTING ACCURACY = 0.9838\n",
            "------------------------------------\n",
            "-----------EPOCH 3------------\n",
            "TRAINING LOSS = 0.06593589915292493\n",
            "TRAINING ACCURACY = 0.9808833333333333\n",
            "TEST LOSS = 0.04469609695195686\n",
            "TESTING ACCURACY = 0.9852\n",
            "------------------------------------\n",
            "-----------EPOCH 4------------\n",
            "TRAINING LOSS = 0.0564296290105752\n",
            "TRAINING ACCURACY = 0.9829666666666667\n",
            "TEST LOSS = 0.04725055487419013\n",
            "TESTING ACCURACY = 0.9853\n",
            "------------------------------------\n",
            "-----------EPOCH 5------------\n",
            "TRAINING LOSS = 0.05164653615385759\n",
            "TRAINING ACCURACY = 0.98515\n",
            "TEST LOSS = 0.04147081316317781\n",
            "TESTING ACCURACY = 0.9872\n",
            "------------------------------------\n",
            "-----------EPOCH 6------------\n",
            "TRAINING LOSS = 0.043718768738423626\n",
            "TRAINING ACCURACY = 0.9877\n",
            "TEST LOSS = 0.04086229484310024\n",
            "TESTING ACCURACY = 0.9882\n",
            "------------------------------------\n",
            "-----------EPOCH 7------------\n",
            "TRAINING LOSS = 0.04671385598892812\n",
            "TRAINING ACCURACY = 0.9867\n",
            "TEST LOSS = 0.048686874919803814\n",
            "TESTING ACCURACY = 0.9853\n",
            "------------------------------------\n",
            "-----------EPOCH 8------------\n",
            "TRAINING LOSS = 0.038524810707652554\n",
            "TRAINING ACCURACY = 0.9887333333333334\n",
            "TEST LOSS = 0.04297872266251943\n",
            "TESTING ACCURACY = 0.9876\n",
            "------------------------------------\n",
            "-----------EPOCH 9------------\n",
            "TRAINING LOSS = 0.03690108402118009\n",
            "TRAINING ACCURACY = 0.98935\n",
            "TEST LOSS = 0.03996265874819074\n",
            "TESTING ACCURACY = 0.9886\n",
            "------------------------------------\n",
            "-----------EPOCH 10------------\n",
            "TRAINING LOSS = 0.03418154828760938\n",
            "TRAINING ACCURACY = 0.9905666666666667\n",
            "TEST LOSS = 0.036299863453659785\n",
            "TESTING ACCURACY = 0.9891\n",
            "------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}