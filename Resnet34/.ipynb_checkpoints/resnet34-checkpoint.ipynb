{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lyxxPixsGz0V"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MBM-ZnJaG54y"
   },
   "outputs": [],
   "source": [
    "class residual_block(nn.Module):\n",
    "  def __init__(self,in_channel,out_channel,downsampling,stride):\n",
    "    super(residual_block,self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_channels=in_channel,out_channels=out_channel,kernel_size=3,stride=stride,padding=1)\n",
    "    self.conv2 = nn.Conv2d(in_channels=out_channel,out_channels=out_channel,kernel_size=3,stride=1,padding=1)\n",
    "    self.bnm = nn.BatchNorm2d(out_channel)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.downsampling = downsampling\n",
    "  \n",
    "  def forward(self,x):\n",
    "    x_input = x\n",
    "    x = self.conv1(x)\n",
    "    x = self.bnm(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.bnm(x)\n",
    "    if self.downsampling == True:\n",
    "      x_input = self.conv1(x_input)\n",
    "    x = x + x_input\n",
    "    x = self.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tRCEljgaKbL1"
   },
   "outputs": [],
   "source": [
    "class resnet(nn.Module):\n",
    "  def __init__(self,num_class):\n",
    "    super(resnet,self).__init__()\n",
    "    self.conv = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=7,stride=2,padding=3)\n",
    "    self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.avgpool = nn.AvgPool2d(kernel_size=7,stride=1,padding=0)\n",
    "    self.bnm = nn.BatchNorm2d(64)\n",
    "    self.relu = nn.ReLU(inplace=True)\n",
    "    self.fc = nn.Linear(in_features=512,out_features=num_class)\n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    self.block_1 = residual_block(64,64,False,1)\n",
    "    self.block_2 = residual_block(64,128,True,2)\n",
    "    self.block_3 = residual_block(128,128,False,1)\n",
    "    self.block_4 = residual_block(128,256,True,2)\n",
    "    self.block_5 = residual_block(256,256,False,1)\n",
    "    self.block_6 = residual_block(256,512,True,2)\n",
    "    self.block_7 = residual_block(512,512,False,1)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.conv(x)\n",
    "    x = self.bnm(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.maxpool(x)\n",
    "    x = self.block_1(x)\n",
    "    x = self.block_1(x)\n",
    "    x = self.block_1(x)\n",
    "    x = self.block_2(x)\n",
    "    x = self.block_3(x)\n",
    "    x = self.block_3(x)\n",
    "    x = self.block_3(x)\n",
    "    x = self.block_4(x)\n",
    "    x = self.block_5(x)\n",
    "    x = self.block_5(x)\n",
    "    x = self.block_5(x)\n",
    "    x = self.block_5(x)\n",
    "    x = self.block_5(x)\n",
    "    x = self.block_6(x)\n",
    "    x = self.block_7(x)\n",
    "    x = self.block_7(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.fc(x)\n",
    "    x = self.softmax(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcpJcsRcKjT0",
    "outputId": "4db5aedd-d51d-4208-d912-aec5f382df24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "   residual_block-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "   residual_block-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "   residual_block-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "           Conv2d-31          [-1, 128, 28, 28]          73,856\n",
      "             ReLU-32          [-1, 128, 28, 28]               0\n",
      "   residual_block-33          [-1, 128, 28, 28]               0\n",
      "           Conv2d-34          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-35          [-1, 128, 28, 28]             256\n",
      "             ReLU-36          [-1, 128, 28, 28]               0\n",
      "           Conv2d-37          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
      "             ReLU-39          [-1, 128, 28, 28]               0\n",
      "   residual_block-40          [-1, 128, 28, 28]               0\n",
      "           Conv2d-41          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-42          [-1, 128, 28, 28]             256\n",
      "             ReLU-43          [-1, 128, 28, 28]               0\n",
      "           Conv2d-44          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-45          [-1, 128, 28, 28]             256\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "   residual_block-47          [-1, 128, 28, 28]               0\n",
      "           Conv2d-48          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
      "             ReLU-50          [-1, 128, 28, 28]               0\n",
      "           Conv2d-51          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
      "             ReLU-53          [-1, 128, 28, 28]               0\n",
      "   residual_block-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 256, 14, 14]         295,168\n",
      "      BatchNorm2d-56          [-1, 256, 14, 14]             512\n",
      "             ReLU-57          [-1, 256, 14, 14]               0\n",
      "           Conv2d-58          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-59          [-1, 256, 14, 14]             512\n",
      "           Conv2d-60          [-1, 256, 14, 14]         295,168\n",
      "             ReLU-61          [-1, 256, 14, 14]               0\n",
      "   residual_block-62          [-1, 256, 14, 14]               0\n",
      "           Conv2d-63          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-64          [-1, 256, 14, 14]             512\n",
      "             ReLU-65          [-1, 256, 14, 14]               0\n",
      "           Conv2d-66          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-67          [-1, 256, 14, 14]             512\n",
      "             ReLU-68          [-1, 256, 14, 14]               0\n",
      "   residual_block-69          [-1, 256, 14, 14]               0\n",
      "           Conv2d-70          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-71          [-1, 256, 14, 14]             512\n",
      "             ReLU-72          [-1, 256, 14, 14]               0\n",
      "           Conv2d-73          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-74          [-1, 256, 14, 14]             512\n",
      "             ReLU-75          [-1, 256, 14, 14]               0\n",
      "   residual_block-76          [-1, 256, 14, 14]               0\n",
      "           Conv2d-77          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-78          [-1, 256, 14, 14]             512\n",
      "             ReLU-79          [-1, 256, 14, 14]               0\n",
      "           Conv2d-80          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
      "             ReLU-82          [-1, 256, 14, 14]               0\n",
      "   residual_block-83          [-1, 256, 14, 14]               0\n",
      "           Conv2d-84          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-85          [-1, 256, 14, 14]             512\n",
      "             ReLU-86          [-1, 256, 14, 14]               0\n",
      "           Conv2d-87          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-88          [-1, 256, 14, 14]             512\n",
      "             ReLU-89          [-1, 256, 14, 14]               0\n",
      "   residual_block-90          [-1, 256, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "   residual_block-97          [-1, 256, 14, 14]               0\n",
      "           Conv2d-98            [-1, 512, 7, 7]       1,180,160\n",
      "      BatchNorm2d-99            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-100            [-1, 512, 7, 7]               0\n",
      "          Conv2d-101            [-1, 512, 7, 7]       2,359,808\n",
      "     BatchNorm2d-102            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-103            [-1, 512, 7, 7]       1,180,160\n",
      "            ReLU-104            [-1, 512, 7, 7]               0\n",
      "  residual_block-105            [-1, 512, 7, 7]               0\n",
      "          Conv2d-106            [-1, 512, 7, 7]       2,359,808\n",
      "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-108            [-1, 512, 7, 7]               0\n",
      "          Conv2d-109            [-1, 512, 7, 7]       2,359,808\n",
      "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-111            [-1, 512, 7, 7]               0\n",
      "  residual_block-112            [-1, 512, 7, 7]               0\n",
      "          Conv2d-113            [-1, 512, 7, 7]       2,359,808\n",
      "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]       2,359,808\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-118            [-1, 512, 7, 7]               0\n",
      "  residual_block-119            [-1, 512, 7, 7]               0\n",
      "       AvgPool2d-120            [-1, 512, 1, 1]               0\n",
      "         Flatten-121                  [-1, 512]               0\n",
      "          Linear-122                 [-1, 1000]         513,000\n",
      "         Softmax-123                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 23,180,648\n",
      "Trainable params: 23,180,648\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 94.96\n",
      "Params size (MB): 88.43\n",
      "Estimated Total Size (MB): 183.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = resnet(1000)\n",
    "summary(model,input_size=(3,224,224))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "resnet34.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
