{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet34.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyxxPixsGz0V"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBM-ZnJaG54y"
      },
      "source": [
        "class residual_block(nn.Module):\n",
        "  def __init__(self,in_channel,out_channel,downsampling,stride):\n",
        "    super(residual_block,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_channel,out_channels=out_channel,kernel_size=3,stride=stride,padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=out_channel,out_channels=out_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bnm = nn.BatchNorm2d(out_channel)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.downsampling = downsampling\n",
        "    self.conv3 = nn.Conv2d(in_channels=in_channel,out_channels=out_channel,kernel_size=3,stride=stride,padding=1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x_input = x\n",
        "    x = self.conv1(x)\n",
        "    x = self.bnm(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bnm(x)\n",
        "    if self.downsampling == True:\n",
        "      x_input = self.conv3(x_input)\n",
        "    x = x + x_input\n",
        "    x = self.relu(x)\n",
        "    return x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRCEljgaKbL1"
      },
      "source": [
        "class resnet(nn.Module):\n",
        "  def __init__(self,num_class):\n",
        "    super(resnet,self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=7,stride=2,padding=3)\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=7,stride=1,padding=0)\n",
        "    self.bnm = nn.BatchNorm2d(64)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "    self.fc = nn.Linear(in_features=512,out_features=num_class)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.block_1 = residual_block(64,64,False,1)\n",
        "    self.block_2 = residual_block(64,128,True,2)\n",
        "    self.block_3 = residual_block(128,128,False,1)\n",
        "    self.block_4 = residual_block(128,256,True,2)\n",
        "    self.block_5 = residual_block(256,256,False,1)\n",
        "    self.block_6 = residual_block(256,512,True,2)\n",
        "    self.block_7 = residual_block(512,512,False,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv(x)\n",
        "    x = self.bnm(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.block_3(x)\n",
        "    x = self.block_3(x)\n",
        "    x = self.block_3(x)\n",
        "    x = self.block_4(x)\n",
        "    x = self.block_5(x)\n",
        "    x = self.block_5(x)\n",
        "    x = self.block_5(x)\n",
        "    x = self.block_5(x)\n",
        "    x = self.block_5(x)\n",
        "    x = self.block_6(x)\n",
        "    x = self.block_7(x)\n",
        "    x = self.block_7(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc(x)\n",
        "    x = self.softmax(x)\n",
        "    return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcpJcsRcKjT0",
        "outputId": "4db5aedd-d51d-4208-d912-aec5f382df24"
      },
      "source": [
        "model = resnet(1000)\n",
        "summary(model,input_size=(3,224,224))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,928\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "   residual_block-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "   residual_block-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
            "             ReLU-21           [-1, 64, 56, 56]               0\n",
            "           Conv2d-22           [-1, 64, 56, 56]          36,928\n",
            "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
            "             ReLU-24           [-1, 64, 56, 56]               0\n",
            "   residual_block-25           [-1, 64, 56, 56]               0\n",
            "           Conv2d-26          [-1, 128, 28, 28]          73,856\n",
            "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
            "             ReLU-28          [-1, 128, 28, 28]               0\n",
            "           Conv2d-29          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
            "           Conv2d-31          [-1, 128, 28, 28]          73,856\n",
            "             ReLU-32          [-1, 128, 28, 28]               0\n",
            "   residual_block-33          [-1, 128, 28, 28]               0\n",
            "           Conv2d-34          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-35          [-1, 128, 28, 28]             256\n",
            "             ReLU-36          [-1, 128, 28, 28]               0\n",
            "           Conv2d-37          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
            "             ReLU-39          [-1, 128, 28, 28]               0\n",
            "   residual_block-40          [-1, 128, 28, 28]               0\n",
            "           Conv2d-41          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-42          [-1, 128, 28, 28]             256\n",
            "             ReLU-43          [-1, 128, 28, 28]               0\n",
            "           Conv2d-44          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-45          [-1, 128, 28, 28]             256\n",
            "             ReLU-46          [-1, 128, 28, 28]               0\n",
            "   residual_block-47          [-1, 128, 28, 28]               0\n",
            "           Conv2d-48          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-49          [-1, 128, 28, 28]             256\n",
            "             ReLU-50          [-1, 128, 28, 28]               0\n",
            "           Conv2d-51          [-1, 128, 28, 28]         147,584\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "   residual_block-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 256, 14, 14]         295,168\n",
            "      BatchNorm2d-56          [-1, 256, 14, 14]             512\n",
            "             ReLU-57          [-1, 256, 14, 14]               0\n",
            "           Conv2d-58          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-59          [-1, 256, 14, 14]             512\n",
            "           Conv2d-60          [-1, 256, 14, 14]         295,168\n",
            "             ReLU-61          [-1, 256, 14, 14]               0\n",
            "   residual_block-62          [-1, 256, 14, 14]               0\n",
            "           Conv2d-63          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-64          [-1, 256, 14, 14]             512\n",
            "             ReLU-65          [-1, 256, 14, 14]               0\n",
            "           Conv2d-66          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-67          [-1, 256, 14, 14]             512\n",
            "             ReLU-68          [-1, 256, 14, 14]               0\n",
            "   residual_block-69          [-1, 256, 14, 14]               0\n",
            "           Conv2d-70          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-71          [-1, 256, 14, 14]             512\n",
            "             ReLU-72          [-1, 256, 14, 14]               0\n",
            "           Conv2d-73          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-74          [-1, 256, 14, 14]             512\n",
            "             ReLU-75          [-1, 256, 14, 14]               0\n",
            "   residual_block-76          [-1, 256, 14, 14]               0\n",
            "           Conv2d-77          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-78          [-1, 256, 14, 14]             512\n",
            "             ReLU-79          [-1, 256, 14, 14]               0\n",
            "           Conv2d-80          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-81          [-1, 256, 14, 14]             512\n",
            "             ReLU-82          [-1, 256, 14, 14]               0\n",
            "   residual_block-83          [-1, 256, 14, 14]               0\n",
            "           Conv2d-84          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-85          [-1, 256, 14, 14]             512\n",
            "             ReLU-86          [-1, 256, 14, 14]               0\n",
            "           Conv2d-87          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-88          [-1, 256, 14, 14]             512\n",
            "             ReLU-89          [-1, 256, 14, 14]               0\n",
            "   residual_block-90          [-1, 256, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         590,080\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "   residual_block-97          [-1, 256, 14, 14]               0\n",
            "           Conv2d-98            [-1, 512, 7, 7]       1,180,160\n",
            "      BatchNorm2d-99            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-100            [-1, 512, 7, 7]               0\n",
            "          Conv2d-101            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-102            [-1, 512, 7, 7]           1,024\n",
            "          Conv2d-103            [-1, 512, 7, 7]       1,180,160\n",
            "            ReLU-104            [-1, 512, 7, 7]               0\n",
            "  residual_block-105            [-1, 512, 7, 7]               0\n",
            "          Conv2d-106            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-107            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-108            [-1, 512, 7, 7]               0\n",
            "          Conv2d-109            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-111            [-1, 512, 7, 7]               0\n",
            "  residual_block-112            [-1, 512, 7, 7]               0\n",
            "          Conv2d-113            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-114            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-115            [-1, 512, 7, 7]               0\n",
            "          Conv2d-116            [-1, 512, 7, 7]       2,359,808\n",
            "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-118            [-1, 512, 7, 7]               0\n",
            "  residual_block-119            [-1, 512, 7, 7]               0\n",
            "       AvgPool2d-120            [-1, 512, 1, 1]               0\n",
            "         Flatten-121                  [-1, 512]               0\n",
            "          Linear-122                 [-1, 1000]         513,000\n",
            "         Softmax-123                 [-1, 1000]               0\n",
            "================================================================\n",
            "Total params: 23,180,648\n",
            "Trainable params: 23,180,648\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 94.96\n",
            "Params size (MB): 88.43\n",
            "Estimated Total Size (MB): 183.96\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}